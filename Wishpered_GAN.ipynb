{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wishpered to GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sjl30A7RuAPjaeVUmUbSvkfYflmIwXXV",
      "authorship_tag": "ABX9TyOeLF2DBWZ2VCA/H0QPuLcn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irfan00785/WHISPERED-TO-VOICED-SPEECH-CONVERSION-WITH-GANS/blob/main/Wishpered_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j92wLfz0Vl9t"
      },
      "source": [
        "### ***Liabraries To Import***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmH4W0F4ndks"
      },
      "source": [
        "#!/usr/bin/python3\n",
        "from __future__ import print_function\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "from collections import namedtuple, OrderedDict\n",
        "from subprocess import call\n",
        "import glob\n",
        "import os\n",
        "import librosa   \n",
        "import soundfile as sf\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wavfile\n",
        "import argparse\n",
        "import codecs\n",
        "import timeit\n",
        "import struct\n",
        "import toml\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "SAMPLE_RATE = 16000 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv9s7OirWoMv"
      },
      "source": [
        "### ***Clean Vocie File Downloading and Processing***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4W355i2aF_C"
      },
      "source": [
        "zipurl = 'https://datashare.ed.ac.uk/bitstream/handle/10283/1942/clean_trainset_wav.zip?sequence=1&isAllowed=y'\n",
        "    # Download the file from the URL\n",
        "zipresp = urlopen(zipurl)\n",
        "    # Create a new file on the hard drive\n",
        "tempzip = open(\"/tmp/tempfile.zip\", \"wb\")\n",
        "    # Write the contents of the downloaded file into the new file\n",
        "tempzip.write(zipresp.read())\n",
        "    # Close the newly-created file\n",
        "tempzip.close()\n",
        "    # Re-open the newly-created file with ZipFile()\n",
        "zf = ZipFile(\"/tmp/tempfile.zip\")\n",
        "    # Extract its contents into <extraction_path>\n",
        "    # note that extractall will automatically create the path\n",
        "zf.extractall(path = 'drive/MyDrive/Wishpered dataset/clean_trainset_wav/')\n",
        "    # close the ZipFile instance\n",
        "zf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qndw1niN6ZzM"
      },
      "source": [
        "\n",
        "#os.mkdir('drive/MyDrive/Wishpered dataset/sampled_testset_wav')\n",
        "\n",
        "file_location = os.path.join('drive','MyDrive','Wishpered dataset','clean_trainset_wav', '*.wav')\n",
        "print(file_location)\n",
        "\n",
        "filenames = glob.glob(file_location)\n",
        "print(filenames)\n",
        "count = 0\n",
        "for f in filenames:\n",
        "  y, sr = librosa.load(f)\n",
        "  data = librosa.resample(y, sr, SAMPLE_RATE)\n",
        "  count += 1\n",
        "  sf.write('drive/MyDrive/Wishpered dataset/sampled_testset_wav/'+os.path.basename(f), data, SAMPLE_RATE)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFO4N-gDW8TU"
      },
      "source": [
        "### ***Noisy Vocie File Downloading and Processing***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtTry2dLcNRE"
      },
      "source": [
        "zipurl = 'https://datashare.ed.ac.uk/bitstream/handle/10283/1942/noisy_trainset_wav.zip?sequence=2&isAllowed=y'\n",
        "    # Download the file from the URL\n",
        "zipresp = urlopen(zipurl)\n",
        "    # Create a new file on the hard drive\n",
        "tempzip = open(\"/tmp/tempfile.zip\", \"wb\")\n",
        "    # Write the contents of the downloaded file into the new file\n",
        "tempzip.write(zipresp.read())\n",
        "    # Close the newly-created file\n",
        "tempzip.close()\n",
        "    # Re-open the newly-created file with ZipFile()\n",
        "zf = ZipFile(\"/tmp/tempfile.zip\")\n",
        "    # Extract its contents into <extraction_path>\n",
        "    # note that extractall will automatically create the path\n",
        "zf.extractall(path = 'drive/MyDrive/Wishpered dataset/noisy_trainset_wav/')\n",
        "    # close the ZipFile instance\n",
        "zf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYDqX4e2ca-B"
      },
      "source": [
        "#os.mkdir('drive/MyDrive/Wishpered dataset/sampled_noisy_trainset_wav')\n",
        "\n",
        "file_location = os.path.join('drive','MyDrive','Wishpered dataset','clean_trainset_wav', '*.wav')\n",
        "print(file_location)\n",
        "\n",
        "filenames = glob.glob(file_location)\n",
        "print(filenames)\n",
        "\n",
        "count = 0\n",
        "for f in filenames:\n",
        "  y, sr = librosa.load(f)\n",
        "  data = librosa.resample(y, sr, SAMPLE_RATE)\n",
        "  count += 1\n",
        "  sf.write('drive/MyDrive/Wishpered dataset/sampled_noisy_trainset_wav/'+os.path.basename(f), data, SAMPLE_RATE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qm3x-8jXF08"
      },
      "source": [
        "### ***Input Pipeline Creation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqh_a-9HUfZo"
      },
      "source": [
        "def _int64_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFoT21OsF_zu"
      },
      "source": [
        "def slice_signal(signal, window_size, stride=0.5):\n",
        "    \"\"\" Return windows of the given signal by sweeping in stride fractions\n",
        "        of window\n",
        "    \"\"\"\n",
        "    assert signal.ndim == 1, signal.ndim\n",
        "    n_samples = signal.shape[0]\n",
        "    offset = int(window_size * stride)\n",
        "    slices = []\n",
        "    for beg_i, end_i in zip(range(0, n_samples, offset),\n",
        "                            range(window_size, n_samples + offset,\n",
        "                                  offset)):\n",
        "        if end_i - beg_i < window_size:\n",
        "            break\n",
        "        slice_ = signal[beg_i:end_i]\n",
        "        if slice_.shape[0] == window_size:\n",
        "            slices.append(slice_)\n",
        "    return np.array(slices, dtype=np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJooH7kxFw89"
      },
      "source": [
        "def read_and_slice(filename, wav_canvas_size, stride=0.5):\n",
        "    fm, wav_data = wavfile.read(filename)\n",
        "    if fm != 16000:\n",
        "        raise ValueError('Sampling rate is expected to be 16kHz!')\n",
        "    signals = slice_signal(wav_data, wav_canvas_size, stride)\n",
        "    return signals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FiQ6q78EqCn"
      },
      "source": [
        "def encoder_proc(wav_filename, noisy_path, out_file, wav_canvas_size):\n",
        "    \"\"\" Read and slice the wav and noisy files and write to TFRecords.\n",
        "        out_file: TFRecordWriter.\n",
        "    \"\"\"\n",
        "    ppath, wav_name = os.path.split(wav_filename)\n",
        "    noisy_filename = os.path.join(noisy_path, wav_name)\n",
        "    wav_signals = read_and_slice(wav_filename, wav_canvas_size)\n",
        "    noisy_signals = read_and_slice(noisy_filename, wav_canvas_size)\n",
        "    assert wav_signals.shape == noisy_signals.shape, noisy_signals.shape\n",
        "\n",
        "    for (wav, noisy) in zip(wav_signals, noisy_signals):\n",
        "        wav_raw = wav.tobytes()\n",
        "        noisy_raw = noisy.tobytes()\n",
        "        example = tf.train.Example(features=tf.train.Features(feature={'wav_raw': _bytes_feature(wav_raw),'noisy_raw': _bytes_feature(noisy_raw)}))\n",
        "        out_file.write(example.SerializeToString())\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMJpeOoJ6abC"
      },
      "source": [
        "save_path ='drive/MyDrive/Wishpered dataset/data/'\n",
        "out_file = 'segan.tfrecords'\n",
        "force_gen = True\n",
        "cfg ='./e2e_maker.cfg'\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "  # make save path if it does not exist\n",
        "  os.makedirs(save_path)\n",
        "# set up the output filepath\n",
        "out_filepath = os.path.join(save_path, out_file)\n",
        "if os.path.splitext(out_filepath)[1] != '.tfrecords':\n",
        "  # if wrong extension or no extension appended, put .tfrecords\n",
        "  out_filepath += '.tfrecords'\n",
        "else:\n",
        "  out_filename, ext = os.path.splitext(out_filepath)\n",
        "  out_filepath = out_filename + ext\n",
        "\n",
        "# check if out_file exists and if force flag is set\n",
        "if os.path.exists(out_filepath) and not force_gen:\n",
        "  raise ValueError('ERROR: {} already exists. Set force flag (--force-gen) to '\n",
        "         'overwrite. Skipping this speaker.'.format(out_filepath))\n",
        "elif os.path.exists(out_filepath) and force_gen:\n",
        "  print('Will overwrite previously existing tfrecords')\n",
        "  os.unlink(out_filepath)\n",
        "\n",
        "count = 0\n",
        "with open(cfg) as cfh:\n",
        "  # read the configuration description\n",
        "  cfg_desc = toml.loads(cfh.read())\n",
        "  beg_enc_t = timeit.default_timer()\n",
        "  out_file = tf.io.TFRecordWriter(out_filepath)\n",
        "  for dset_i, (dset, dset_desc) in enumerate(cfg_desc.items()):\n",
        "    print('-' * 50)\n",
        "    wav_dir = dset_desc['clean']\n",
        "    wav_files = [os.path.join(wav_dir, wav) for wav in\n",
        "                           os.listdir(wav_dir) if wav.endswith('.wav')]\n",
        "    noisy_dir = dset_desc['noisy']\n",
        "    nfiles = len(wav_files)\n",
        "    for m, wav_file in enumerate(wav_files):\n",
        "      sys.stdout.flush()\n",
        "      print('Processing wav file {}/{} {}{}'.format(m + 1,nfiles,wav_file,' ' * 10))\n",
        "      encoder_proc(wav_file, noisy_dir, out_file, 2 ** 14)\n",
        "      count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuMy6ox4XShb"
      },
      "source": [
        "### ***Model Building***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5_861668yNb"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "save_path = \"segan_results\"\n",
        "synthesis_path = \"dwavegan_samples\"\n",
        "model = 'gan'\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)           #Path to save out model files. (Def: dwavegan_model). \n",
        "if not os.path.exists(synthesis_path):\n",
        "        os.makedirs(synthesis_path)      #Path to save output generated samples.(Def: dwavegan_samples)\n",
        "\n",
        "\n",
        "devices = device_lib.list_local_devices()\n",
        "udevices = []\n",
        "for device in devices:\n",
        "        if len(devices) > 1 and 'cpu' in device.name:\n",
        "            # Use cpu only when we dont have gpus\n",
        "            continue\n",
        "        print('Using device: ', device.name)\n",
        "        udevices.append(device.name)\n",
        "\n",
        "if model == 'gan':\n",
        "  print('Creating GAN model')\n",
        "  se_model = SEGAN(sess, FLAGS, udevices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afa3glm4XdKN"
      },
      "source": [
        "### ***Data Loader***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2somM7MWpbIz"
      },
      "source": [
        "def pre_emph(x, coeff=0.95):\n",
        "    x0 = tf.reshape(x[0], [1,])\n",
        "    diff = x[1:] - coeff * x[:-1]\n",
        "    concat = tf.concat([x0, diff], 0)\n",
        "    return concat\n",
        "\n",
        "\n",
        "def read_and_decode(filename_queue, canvas_size, preemph=0.):\n",
        "  wave = 0\n",
        "  noisy = 0\n",
        "  reader = tf.compat.v1.TFRecordReader()\n",
        "  _, serialized_example = reader.read(filename_queue)\n",
        "  features = tf.io.parse_single_example(\n",
        "            serialized_example,\n",
        "            features={\n",
        "                'wav_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "                'noisy_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "            })\n",
        "  wave = tf.io.decode_raw(features['wav_raw'], tf.int32)\n",
        "  wave.set_shape(canvas_size)\n",
        "  wave = (2./65535.) * tf.cast((wave - 32767), tf.float32) + 1.\n",
        "  noisy = tf.io.decode_raw(features['noisy_raw'], tf.int32)\n",
        "  noisy.set_shape(canvas_size)\n",
        "  noisy = (2./65535.) * tf.cast((noisy - 32767), tf.float32) + 1.\n",
        "\n",
        "  \n",
        "  if preemph > 0:\n",
        "        wave = tf.cast(pre_emph(wave, preemph), tf.float32)\n",
        "        noisy = tf.cast(pre_emph(noisy, preemph), tf.float32)\n",
        "  return wave, noisy"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRXdmZsGHgVr"
      },
      "source": [
        "e2e_dataset = \"drive/MyDrive/Wishpered dataset/data/segan.tfrecords\"\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "filename_queue = tf.compat.v1.train.string_input_producer([e2e_dataset])\n",
        "canvas_size = 2**14\n",
        "preemph = 0.95\n",
        "batch_size = 150\n",
        "g_enc_depths = [16, 32, 32, 64, 64, 128, 128, 256, 256, 512, 1024]\n",
        "g_dilated_blocks = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
        "\n",
        "Gs = []\n",
        "zs = []\n",
        "gtruth_wavs = []\n",
        "gtruth_noisy = []\n",
        "\n",
        "\n",
        "get_wav, get_noisy = read_and_decode(filename_queue, canvas_size, preemph)\n",
        "\n",
        "wavbatch, noisybatch = tf.compat.v1.train.shuffle_batch([get_wav,\n",
        "                                             get_noisy],\n",
        "                                             batch_size=batch_size,\n",
        "                                             num_threads=2,\n",
        "                                             capacity=1000 + 3 * batch_size,\n",
        "                                             min_after_dequeue=1000,\n",
        "                                             name='wav_and_noisy')\n",
        "\n",
        "gtruth_wavs.append(wavbatch)\n",
        "gtruth_noisy.append(noisybatch)\n",
        "\n",
        "# add channels dimension to manipulate in D and G\n",
        "wavbatch = tf.expand_dims(wavbatch, -1)\n",
        "noisybatch = tf.expand_dims(noisybatch, -1)\n",
        "\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZgnZ8UtVpUS"
      },
      "source": [
        "## ***MODEL GENERATION***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07JiDLqr7950"
      },
      "source": [
        "#Dilated Convolution \n",
        "\n",
        "def atrous_conv1d(value, dilation, kwidth=3, num_kernels=1,\n",
        "                  name='atrous_conv1d', bias_init=None, stddev=0.02):\n",
        "    input_shape = value.get_shape().as_list()\n",
        "    in_channels = input_shape[-1]\n",
        "    assert len(input_shape) >= 3\n",
        "    with tf.compat.v1.variable_scope(name):\n",
        "        weights_init = tf.compat.v1.truncated_normal_initializer(stddev=0.02)\n",
        "        # filter shape: [kwidth, in_channels, output_channels]\n",
        "        filter_ = tf.compat.v1.get_variable('w', [kwidth, in_channels, num_kernels],initializer=weights_init,)\n",
        "        padding = [[0, 0], [(kwidth/2) * dilation, (kwidth/2) * dilation],[0, 0]]\n",
        "\n",
        "        #print(value)\n",
        "        padded = tf.compat.v1.pad(value, padding, mode='SYMMETRIC')\n",
        "        if dilation > 1:\n",
        "            transformed = time_to_batch(padded, dilation)\n",
        "            conv = tf.nn.conv1d(transformed, filter_, stride=1, padding='SAME')\n",
        "            restored = batch_to_time(conv, dilation)\n",
        "        else:\n",
        "            restored = tf.nn.conv1d(padded, filter_, stride=1, padding='SAME')\n",
        "        # Remove excess elements at the end.\n",
        "        result = tf.slice(restored,\n",
        "                          [0, 0, 0],\n",
        "                          [-1, input_shape[1], num_kernels])\n",
        "        if bias_init is not None:\n",
        "            b = tf.get_variable('b', [num_kernels],\n",
        "                                initializer=tf.constant_initializer(bias_init))\n",
        "            result = tf.add(result, b)\n",
        "        return result"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "floqivpFoSHf"
      },
      "source": [
        "#Residual Block\n",
        "\n",
        "def residual_block(input_, dilation, kwidth, num_kernels=1,bias_init=None, stddev=0.02, do_skip=True,name='residual_block'):\n",
        "  print('input shape to residual block: ', input_.get_shape())\n",
        "  with tf.compat.v1.variable_scope(name):\n",
        "    #h_a = tf.keras.layers.Conv1D(dilation_rate = dilation, kernel_size = kwidth, filters=num_kernels,\n",
        "                            #bias_initializer=bias_init,input_shape=input_.get_shape().as_list())(input_)\n",
        "\n",
        "    h_a = atrous_conv1d(input_, dilation, kwidth, num_kernels,\n",
        "                            bias_init=bias_init, stddev=stddev)\n",
        "    h = tf.tanh(h_a)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXGbnpA3cKf2"
      },
      "source": [
        "#Shaping the z value\n",
        "def make_z(shape,is_ref, mean=0., std=1., name='z'):\n",
        "  if is_ref:\n",
        "    with tf.variable_scope(name) as scope:\n",
        "      z_init = tf.random_normal_initializer(mean=mean, stddev=std)\n",
        "      z = tf.get_variable(\"z\", shape,initializer=z_init,trainable=False)\n",
        "      if z.device != \"/device:GPU:0\":\n",
        "        # this has to be created into gpu0\n",
        "        print('z.device is {}'.format(z.device))\n",
        "        assert False\n",
        "  else:\n",
        "    z = tf.random.normal(shape, mean=mean, stddev=std,name=name, dtype=tf.float32)\n",
        "  return z"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy5TWfeMZHMO"
      },
      "source": [
        "#Generator Model Defination\n",
        "\n",
        "def generator(noisy_w, is_ref, spk=None, do_prelu = False):\n",
        "  tf.compat.v1.get_variable_scope().reuse_variables()\n",
        "\n",
        "  print('*** Building Generator ***')\n",
        "  in_dims = noisy_w.get_shape().as_list()\n",
        "  h_i = noisy_w\n",
        "  if len(in_dims) == 2:\n",
        "    h_i = tf.expand_dims(noisy_w, -1)\n",
        "  elif len(in_dims) < 2 or len(in_dims) > 3:\n",
        "    raise ValueError('Generator input must be 2-D or 3-D')\n",
        "\n",
        "  kwidth = 3\n",
        "  z = make_z([batch_size, h_i.get_shape().as_list()[1],g_enc_depths[-1]],is_ref)\n",
        "  h_i = tf.concat([h_i, z],2)\n",
        "  skip_out = True\n",
        "  skips = []\n",
        "  for block_idx, dilation in enumerate(g_dilated_blocks):\n",
        "    name = 'g_residual_block_{}'.format(block_idx)\n",
        "    if block_idx >= len(g_dilated_blocks) - 1:\n",
        "      skip_out = False\n",
        "    if skip_out:\n",
        "      skip_i = residual_block(h_i,dilation, kwidth, num_kernels=32, bias_init=None, stddev=0.02,do_skip = True,name=name)\n",
        "    \n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8-Q7q0MY4jr"
      },
      "source": [
        "g_nl = 'prelu'\n",
        "\n",
        "prelu = False\n",
        "if g_nl == 'prelu':\n",
        "  prelu = True\n",
        "\n",
        "z  = generator(noisybatch, is_ref=False, spk=None, do_prelu=prelu)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}